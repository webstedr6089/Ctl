{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/webstedr6089/ctl/blob/main/CTL_Final_Project_BAA_Data_Extraction_into_Spreadsheet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "952f253b",
      "metadata": {
        "id": "952f253b"
      },
      "source": [
        "# Colab for Extracting Data from Business Associate Agreements (in OCRed PDF format) into a Google Spreadsheet Using OpenAI.\n",
        "\n",
        "_**Warning:** When using LLMs for entity extraction, be sure to perform extensive quality control. They are very susceptible to distracting language (latching on to text that sounds \"kind of like\" what you're looking for) and missing language (making up content to fill any holes), and importantly, they do **NOT** provide any hints to when they may be erroring. You need to make sure random audits are part of your workflow!_ Below we've worked out a workflow using regular expressions and LLMs to parse data from zoning board orders, but the process is generalizable.\n",
        "\n",
        "1. Collect a set of BAAs in an OCRed PDF format\n",
        "2. Place the PDFs [here](https://drive.google.com/drive/folders/1YPrPzQTV-D9smX7ufD92W24UCRkggcAG?usp=drive_link).\n",
        "3. Select run\n",
        "4. View the output [here](https://docs.google.com/spreadsheets/d/1kIRI_7g8ThGms7mCrqUdiVeAffqoeG7Xl5i8cCbVZaM/edit?usp=sharing)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Libraries\n",
        "\n",
        "\n",
        "First we load the libraries we need. Note, if you try to run the cell, and you get something like `ModuleNotFoundError: No module named 'mod_name'`, you'll need to install the module. You can do this commentating the line below that reads `#!pip install mod_name` if it's listed. If it isn't, you can probably install it with a similarly formatted command."
      ],
      "metadata": {
        "id": "2ZWAyYXE9GyU"
      },
      "id": "2ZWAyYXE9GyU"
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install os\n",
        "!pip install PyPDF2\n",
        "#!pip install re\n",
        "#!pip install pandas\n",
        "#!pip install numpy"
      ],
      "metadata": {
        "id": "yVAfiYiBrjDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eefcbea-20db-4e64-c729-8734425a7c3f"
      },
      "id": "yVAfiYiBrjDT",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install openai\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "-Kr4NiHRr08y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1516de99-5e49-4d8b-b96b-69d502540ec0"
      },
      "id": "-Kr4NiHRr08y",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.6.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.26.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b08c931e",
      "metadata": {
        "id": "b08c931e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os import walk, path\n",
        "import PyPDF2\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def read_pdf(file):\n",
        "    try:\n",
        "        pdfFile = PyPDF2.PdfReader(open(file, \"rb\"), strict=False)\n",
        "        text = \"\"\n",
        "        for page in pdfFile.pages:\n",
        "            text += \" \" + page.extract_text()\n",
        "        return text\n",
        "    except:\n",
        "        return \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2ea2e95c",
      "metadata": {
        "id": "2ea2e95c"
      },
      "outputs": [],
      "source": [
        "# Test Audio call\n",
        "# Only works on Mac. If you aren't using a Mac, you should disable such calls below.\n",
        "#tmp = os.system( \"say Testing, testing, one, two, three.\")\n",
        "#del(tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9e90a53d",
      "metadata": {
        "id": "9e90a53d"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "import openai\n",
        "from transformers import GPT2TokenizerFast\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
        "\n",
        "import tiktoken\n",
        "ENCODING = \"gpt2\"\n",
        "encoding = tiktoken.get_encoding(ENCODING)\n",
        "\n",
        "def complete_text(prompt,temp=0,trys=0,clean=True):\n",
        "\n",
        "    global tokens_used\n",
        "\n",
        "    model=\"text-davinci-003\"\n",
        "    model_token_limit = 4097\n",
        "\n",
        "    token_count = len(encoding.encode(prompt))\n",
        "    max_tokens= model_token_limit-round(token_count+5)\n",
        "\n",
        "    #try:\n",
        "    response = openai.Completion.create(\n",
        "      model=model,\n",
        "      prompt=prompt,\n",
        "      temperature=temp,\n",
        "      max_tokens=max_tokens,\n",
        "      top_p=1.0,\n",
        "      frequency_penalty=0.0,\n",
        "      presence_penalty=0.0\n",
        "    )\n",
        "    output = str(response[\"choices\"][0][\"text\"].strip())\n",
        "    #except:\n",
        "    #    print(\"Problem with API call!\")\n",
        "    #    output = \"\"\"{\"output\":\"error\"}\"\"\"\n",
        "\n",
        "    tokens_used += token_count+len(encoding.encode(output))\n",
        "\n",
        "    if clean:\n",
        "        return clean_pseudo_json(output,temp=0,trys=trys)\n",
        "    else:\n",
        "        return output\n",
        "\n",
        "def clean_pseudo_json(string,temp=0,key=\"output\",trys=0,ask_for_help=1):\n",
        "    try:\n",
        "        output = json.loads(string)[key]\n",
        "    except:\n",
        "        try:\n",
        "            string_4_json = re.findall(\"\\{.*\\}\",re.sub(\"\\n\",\"\",string))[0]\n",
        "            output = json.loads(string_4_json)[key]\n",
        "        except:\n",
        "            try:\n",
        "                string = \"{\"+string+\"}\"\n",
        "                string_4_json = re.findall(\"\\{.*\\}\",re.sub(\"\\n\",\"\",string))[0]\n",
        "                output = json.loads(string_4_json)[key]\n",
        "            except Exception as e:\n",
        "                prompt = \"I tried to parse some json and got this error, '{}'. This was the would-be json.\\n\\n{}\\n\\nReformat it to fix the error.\".format(e,string)\n",
        "                if trys <= 3:\n",
        "                    if trys == 0:\n",
        "                        warm_up = 0\n",
        "                    else:\n",
        "                        warm_up = 0.25\n",
        "                    output = complete_text(prompt,temp=0+warm_up,trys=trys+1)\n",
        "                    print(\"\\n\"+str(output)+\"\\n\")\n",
        "                elif ask_for_help==1:\n",
        "                    print(prompt+\"\\nReformaing FAILED!!!\")\n",
        "                    #try:\n",
        "                    #    os.system( \"say hey! I need some help. A little help please?\")\n",
        "                    #except:\n",
        "                    #    print(\"'say' not supported.\\n\\n\")\n",
        "                    output = input(\"Let's see if we can avoid being derailed. Examine the above output and construct your own output text. Then enter it below. If the output needs to be something other than a string, e.g., a list or json, start it with `EVAL: `. If you're typing that, be very sure there's no malicious code in the output.\\n\")\n",
        "                    if output[:6]==\"EVAL: \":\n",
        "                        output = eval(output[6:])\n",
        "                else:\n",
        "                    output = \"There was an error getting a reponse!\"\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e011e2f",
      "metadata": {
        "id": "9e011e2f"
      },
      "source": [
        "# Input OpenAI API Key & LLM settings\n",
        "\n",
        "You'll need an API key to use an LLM. After creating an OpenAI account, you can create an API key here: https://platform.openai.com/account/api-keys\n",
        "\n",
        "Enter your key between the quation marks next to `openai.api_key =` below, and run that cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af39423f",
      "metadata": {
        "id": "af39423f"
      },
      "outputs": [],
      "source": [
        "# Toggle LLM usage on or off\n",
        "use_LLM = True\n",
        "\n",
        "llm_temperature = 0 # I strongly suggest keeping the LLM's temp at zero to avoid it making things up.\n",
        "\n",
        "openai.api_key = \"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\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2eae960",
      "metadata": {
        "id": "e2eae960"
      },
      "source": [
        "# Load and pase files\n",
        "Next, place a bunch of OCRed pdf files in the right folder (here, the `/content/gdrive/entity_extraction_sample_data/boston/` folder). FWIW, you can use Adobe Pro to OCR in batch. Note: to make your files visisble at a location like that above, you'll need to add them to your Google Drive. E.g., you would need to copy https://drive.google.com/drive/folders/1H3bMgxzNxwxNL2YK6eMWt3nX985oBqVS?usp=sharing to your GDrive and name it `entity_extraction_sample_data` for it to be accessable at `/content/gdrive/entity_extraction_sample_data/`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this mounts your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "D83o_cPAsi07"
      },
      "id": "D83o_cPAsi07",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame() #this will create an empty dataframe\n",
        "\n",
        "# list the files in the drive\n",
        "filepath = \"/content/gdrive/MyDrive/entity_extraction_sample_data/boston/\" # this is where we'll be looking for files\n",
        "f = []\n",
        "for (dirpath, dirnames, filenames) in walk(filepath): # create a list of file names\n",
        "    f.extend(filenames)\n",
        "    break\n",
        "\n",
        "f #show list"
      ],
      "metadata": {
        "id": "McJWfAD431ge"
      },
      "id": "McJWfAD431ge",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feeaf722",
      "metadata": {
        "scrolled": false,
        "id": "feeaf722"
      },
      "outputs": [],
      "source": [
        "sample = 2\n",
        "#sample = len(f) #if you want to go through all the files, uncomment this line and comment out the above\n",
        "\n",
        "token_counts = []\n",
        "for file in random.choices(f,k=sample): # for each file in the list of file names, do some stuff\n",
        "\n",
        "    tokens_used = 0\n",
        "\n",
        "    column_names = [\"file\"]\n",
        "    column_values = [file]\n",
        "\n",
        "    fileloc = filepath+file\n",
        "    text = read_pdf(fileloc)\n",
        "    #print(\"text here: \", text)\n",
        "    words = len(text.split())\n",
        "\n",
        "    print(\"Parsing ~{} words ({} tokens) from: \\\"{}\\\"\\n\".format(words,len(encoding.encode(text)),fileloc))\n",
        "\n",
        "    #############################################################\n",
        "    # Here's where we use regex to pull out specific content\n",
        "\n",
        "    try:\n",
        "      # ---------------------------------------------------------\n",
        "      # case Number\n",
        "      # ---------------------------------------------------------\n",
        "      case_no = re.search(\"(?<=case no\\.\\s)(.*?)(?=perm)\",text, flags=re.IGNORECASE).groups(0)[0].strip()\n",
        "      column_names.append(\"case_no\")\n",
        "      column_values.append(case_no)\n",
        "    except:\n",
        "      column_names.append(\"case_no\")\n",
        "      column_values.append(\"NA\")\n",
        "\n",
        "    try:\n",
        "      # ---------------------------------------------------------\n",
        "      # address\n",
        "      # ---------------------------------------------------------\n",
        "      address = re.search(\"(?<=concerning premises\\s)(.*?)(?=\\s?,?\\s?ward)\",text, flags=re.IGNORECASE).groups(0)[0].strip()\n",
        "      column_names.append(\"address\")\n",
        "      column_values.append(address)\n",
        "    except:\n",
        "      column_names.append(\"address\")\n",
        "      column_values.append(\"NA\")\n",
        "\n",
        "    try:\n",
        "      # ---------------------------------------------------------\n",
        "      # ward\n",
        "      # ---------------------------------------------------------\n",
        "      ward = re.search(\"(?<=ward\\s)(.*?)(?=to vary)\",text, flags=re.IGNORECASE).groups(0)[0].strip()\n",
        "      column_names.append(\"ward\")\n",
        "      column_values.append(ward)\n",
        "    except:\n",
        "      column_names.append(\"ward\")\n",
        "      column_values.append(\"NA\")\n",
        "\n",
        "\n",
        "    #############################################################\n",
        "    # Here's where use GPT to pull out some specific content.\n",
        "\n",
        "    #\n",
        "    # Note: You should consider combining multiple prompts into a single prompt\n",
        "    # to avoid making unnecessary api calls. See e.g. Reasoning & Decision below\n",
        "    #\n",
        "\n",
        "    if use_LLM:\n",
        "\n",
        "      try:\n",
        "        # ---------------------------------------------------------\n",
        "        # description of variance requested\n",
        "        # ---------------------------------------------------------\n",
        "        prompt_text = \"\"\"Below you will be provided with the text of an order from a local zoning board of appeals responding to a variance request. You're looking to find the _description of variance requested_. That is, what the petitioner was asking for.\n",
        "\n",
        "    Here's the text of the order.\n",
        "\n",
        "    {}\n",
        "\n",
        "    ---\n",
        "\n",
        "    Return a json object, including the outermost currly brakets, where the key is \"output\" and the value is a the _description of variance requested_. If you can't find a _description of variance requested_ in the text of the above, answer \"none found\". Be sure to use valid json, encasing keys and values in double quotes, and escaping internal quotes and special characters as needed.\"\"\". format(text)\n",
        "        #print(prompt_text)\n",
        "        request = complete_text(prompt_text,temp=llm_temperature)\n",
        "        column_names.append(\"request\")\n",
        "        column_values.append(request)\n",
        "      except:\n",
        "        column_names.append(\"request\")\n",
        "        column_values.append(\"NA\")\n",
        "\n",
        "      try:\n",
        "        # ---------------------------------------------------------\n",
        "        # relevant facts\n",
        "        # ---------------------------------------------------------\n",
        "        prompt_text = \"\"\"Below you will be provided with the text of an order from a local zoning board of appeals responding to a variance request. You're looking to find the _relevant facts_. That is, what facts did the board needed to know to rule on the petitioner's request.\n",
        "\n",
        "    Here's the text of the order.\n",
        "\n",
        "    {}\n",
        "\n",
        "    ---\n",
        "\n",
        "    Return a json object, including the outermost currly brakets, where the key is \"output\" and the value is a a short summary of the _relevant facts_. If you can't find _relevant facts_ in the text of the above, answer \"none found\". Be sure to use valid json, encasing keys and values in double quotes, and escaping internal quotes and special characters as needed.\"\"\". format(text)\n",
        "        #print(prompt_text)\n",
        "        facts = complete_text(prompt_text,temp=llm_temperature)\n",
        "        column_names.append(\"facts\")\n",
        "        column_values.append(facts)\n",
        "      except:\n",
        "        column_names.append(\"facts\")\n",
        "        column_values.append(\"NA\")\n",
        "\n",
        "      try:\n",
        "        # ---------------------------------------------------------\n",
        "        # reasoning & decision\n",
        "        # ---------------------------------------------------------\n",
        "        prompt_text = \"\"\"Below you will be provided with the text of an order from a local zoning board of appeals responding to a variance request. You're looking to find the board's _decision_ and _reasoning_. That is, how the board ruled on the petitioner's request and how it came to that decision.\n",
        "\n",
        "    Here's the text of the order.\n",
        "\n",
        "    {}\n",
        "\n",
        "    ---\n",
        "\n",
        "    Return a json object, including the outermost currly brakets, where the key is \"output\" and the value is a json object with two key-value pairs: (1) the first item has the key \"reasoning\" and the value is a summary of the board's _reasoning_ as stated above; and (2) the second item has a the key \"decision\" with a value that is a one or two word re-statment of the _decision_ found above (e.g., \"granted,\" \"not granted,\" or \"granted in part\"). If you can't find the _decision_ or _reasoning_ in the text of the above order, both values should read \"none found\". Be sure to use valid json, encasing keys and values in double quotes, and escaping internal quotes and special characters as needed.\"\"\". format(text)\n",
        "        #print(prompt_text)\n",
        "        output = complete_text(prompt_text,temp=llm_temperature)\n",
        "\n",
        "        reasoning = output[\"reasoning\"]\n",
        "        column_names.append(\"reasoning\")\n",
        "        column_values.append(reasoning)\n",
        "\n",
        "        decision = output[\"decision\"]\n",
        "        column_names.append(\"decision\")\n",
        "        column_values.append(decision)\n",
        "      except:\n",
        "\n",
        "        column_names.append(\"reasoning\")\n",
        "        column_values.append(\"NA\")\n",
        "\n",
        "        column_names.append(\"decision\")\n",
        "        column_values.append(\"NA\")\n",
        "\n",
        "\n",
        "    #############################################################\n",
        "\n",
        "    # After testing or when working with large numbers, you may want to comment this next bit out\n",
        "\n",
        "    # Show your work\n",
        "    i = 0\n",
        "    for datum in column_values:\n",
        "        print(\"{}: {}\\n\".format(column_names[i].upper(),datum))\n",
        "        i+=1\n",
        "\n",
        "\n",
        "    # Show cost per run\n",
        "    if use_LLM:\n",
        "        print(\"Tokens used (approx.): {} (API Cost ~${})\\n\".format(tokens_used,tokens_used*(0.002/1000))) # See https://openai.com/pricing\n",
        "        token_counts.append(tokens_used)\n",
        "\n",
        "    print(\"================================================\\n\")\n",
        "\n",
        "    df = pd.concat([df,pd.DataFrame([column_values],columns=column_names)], ignore_index=True,sort=False)\n",
        "\n",
        "print(\"Average approx. tokens used per item {} (API Cost ~${})\\n\".format(np.array(token_counts).mean(),np.array(token_counts).mean()*(0.002/1000))) # See https://openai.com/pricing\n",
        "\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aeef32c",
      "metadata": {
        "id": "9aeef32c"
      },
      "outputs": [],
      "source": [
        "# If you're happy with the stuff you pulled out above, you can write the df to a csv file\n",
        "# make sure the path is placing it where you want it!\n",
        "\n",
        "df.to_csv(\"/content/gdrive/MyDrive/entity_extraction_sample_data/Coding of Boston Variance Decisions.csv\", index=False, encoding=\"utf-8\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2ZWAyYXE9GyU"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}